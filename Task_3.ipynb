{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAYaFjTijpoz",
        "outputId": "a0d2ebe6-78cd-480b-8d51-d84e4831f3e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.1.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.26 (from langchain_groq)\n",
            "  Downloading langchain_core-0.2.35-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting distro<2,>=1.7.0 (from groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting pydantic<3,>=1.9.0 (from groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
            "Collecting sniffio (from groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\shiva\\appdata\\roaming\\python\\python310\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Collecting PyYAML>=5.3 (from langchain-core<0.3.0,>=0.2.26->langchain_groq)\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.26->langchain_groq)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.75 (from langchain-core<0.3.0,>=0.2.26->langchain_groq)\n",
            "  Downloading langsmith-0.1.104-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (23.2)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core<0.3.0,>=0.2.26->langchain_groq)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting idna>=2.8 (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading idna-3.8-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\shiva\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Collecting certifi (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain_groq)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq)\n",
            "  Downloading orjson-3.10.7-cp310-none-win_amd64.whl.metadata (51 kB)\n",
            "Collecting requests<3,>=2 (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.20.1 (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading pydantic_core-2.20.1-cp310-none-win_amd64.whl.metadata (6.7 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq)\n",
            "  Using cached charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl.metadata (34 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq)\n",
            "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "Downloading langchain_groq-0.1.9-py3-none-any.whl (14 kB)\n",
            "Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "Downloading langchain_core-0.2.35-py3-none-any.whl (394 kB)\n",
            "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
            "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langsmith-0.1.104-py3-none-any.whl (149 kB)\n",
            "Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
            "Downloading pydantic_core-2.20.1-cp310-none-win_amd64.whl (1.9 MB)\n",
            "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
            "   ----- ---------------------------------- 0.3/1.9 MB ? eta -:--:--\n",
            "   ---------------- ----------------------- 0.8/1.9 MB 1.8 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 1.3/1.9 MB 2.0 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 1.8/1.9 MB 2.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.9/1.9 MB 2.0 MB/s eta 0:00:00\n",
            "Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
            "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading idna-3.8-py3-none-any.whl (66 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading orjson-3.10.7-cp310-none-win_amd64.whl (137 kB)\n",
            "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
            "Using cached charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl (100 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
            "Installing collected packages: urllib3, tenacity, sniffio, PyYAML, pydantic-core, orjson, jsonpointer, idna, h11, distro, charset-normalizer, certifi, annotated-types, requests, pydantic, jsonpatch, httpcore, anyio, httpx, langsmith, groq, langchain-core, langchain_groq\n",
            "Successfully installed PyYAML-6.0.2 annotated-types-0.7.0 anyio-4.4.0 certifi-2024.7.4 charset-normalizer-3.3.2 distro-1.9.0 groq-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 idna-3.8 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.2.35 langchain_groq-0.1.9 langsmith-0.1.104 orjson-3.10.7 pydantic-2.8.2 pydantic-core-2.20.1 requests-2.32.3 sniffio-1.3.1 tenacity-8.5.0 urllib3-2.2.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain_groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RJL_KMNkj-i0"
      },
      "outputs": [],
      "source": [
        "api_key = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu1EBwMilB4V"
      },
      "source": [
        "**Q1)**\n",
        "\n",
        "**Zero shot prompting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JftLHdvAk9_m",
        "outputId": "c2e46828-3d4f-4a86-e90f-c1d4e5d80d1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape:  (126, 500, 3)\n",
            "Testing data shape:  (54, 500, 3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:151: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "All predicted labels:\n",
            "[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 0, 4, 2, 0, 4, 4, 4, 4, 4, 2, 4, 3, 4, 4, 4, 4, 4, 3, 0, 4, 0, 4, 0, 0, 3, 4, 3, 0, 2, 2, 2, 4, 4, 4, 4, 4, 4]\n",
            "\n",
            " All True lables:\n",
            "[3 1 2 5 5 1 1 5 3 2 6 5 6 5 6 1 6 5 2 5 4 3 2 2 1 4 6 4 1 2 6 2 4 4 3 6 6\n",
            " 3 1 5 3 2 1 4 4 4 5 1 3 3 3 6 2 4]\n",
            "\n",
            "Accuracy: 0.1111111111111111\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from langchain_groq.chat_models import ChatGroq\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from HAR.MakeDataset import X_train,X_test,y_train,y_test\n",
        "\n",
        "\n",
        "\n",
        "label_mapping = {\n",
        "    \"LAYING\": 1,\n",
        "    \"SITTING\": 2,\n",
        "    \"STANDING\": 3,\n",
        "    \"WALKING\": 4,\n",
        "    \"WALKING_DOWNWARDS\": 5,\n",
        "    \"WALKING_UPWARDS\": 6\n",
        "}\n",
        "model_name = \"llama3.1-8b\"\n",
        "model = ChatGroq(api_key=api_key)\n",
        "# Function to format a single example for zero-shot learning\n",
        "def format_example(example):\n",
        "    ax = example[:, 0]\n",
        "    ay = example[:, 1]\n",
        "    az = example[:, 2]\n",
        "\n",
        "    ax_str = \", \".join(map(str, ax))\n",
        "    ay_str = \", \".join(map(str, ay))\n",
        "    az_str = \", \".join(map(str, az))\n",
        "\n",
        "    # Simplified prompt\n",
        "    formatted_string = (\n",
        "        f\"Classify the activity based on the following accelerometer data:\\n\"\n",
        "        f\"ax: [{ax_str}]\\n\"\n",
        "        f\"ay: [{ay_str}]\\n\"\n",
        "        f\"az: [{az_str}]\\n\"\n",
        "        f\"Activity: \"\n",
        "    )\n",
        "\n",
        "    return formatted_string\n",
        "\n",
        "# Prepare input examples from x_test\n",
        "formatted_examples = [format_example(example) for example in X_test]\n",
        "\n",
        "# Perform zero-shot prediction and print raw predictions\n",
        "y_pred = [model.predict(example) for example in formatted_examples]\n",
        "\n",
        "# Extract activity labels from the model's response\n",
        "def extract_label(response):\n",
        "    match = re.search(r'\\b(LAYING|SITTING|STANDING|WALKING|WALKING_DOWNWARDS|WALKING_UPWARDS)\\b', response.upper())\n",
        "    return match.group(0) if match else \"UNKNOWN\"\n",
        "\n",
        "# Convert predictions to numeric labels\n",
        "y_pred_labels = [label_mapping.get(extract_label(pred), 0) for pred in y_pred]\n",
        "\n",
        "# Print raw predictions, predicted labels, and actual labels for the first 10 samples\n",
        "#print(\"Example\\tRaw Prediction\\tPredicted Label\\tActual Label\")\n",
        "for i in range(5):\n",
        "    raw_pred = y_pred[i]\n",
        "    pred_label = label_mapping.get(extract_label(raw_pred), 0)\n",
        "    actual_label = y_test[i]\n",
        "    #print(f\"{i+1}\\t{raw_pred}\\t{pred_label}\\t{actual_label}\")\n",
        "\n",
        "# Print the numeric predictions for all samples\n",
        "print(\"\\nAll predicted labels:\")\n",
        "print(y_pred_labels)\n",
        "print(\"\\n All True lables:\")\n",
        "print(y_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_labels)\n",
        "print(f\"\\nAccuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFDFeuJFkpmi"
      },
      "source": [
        "**2) Few shot prompting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNtAGt2ijcB_",
        "outputId": "cf44b0b0-ae69-4cb2-b0bd-2851f4fe3c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All predicted labels:\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "All True labels:\n",
            "[3 1 2 5 5 1 1 5 3 2 6 5 6 5 6 1 6 5 2 5 4 3 2 2 1 4 6 4 1 2 6 2 4 4 3 6 6\n",
            " 3 1 5 3 2 1 4 4 4 5 1 3 3 3 6 2 4]\n",
            "Accuracy: 0.16666666666666666\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from langchain_groq.chat_models import ChatGroq\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from HAR.MakeDataset import X_train,X_test,y_train,y_test\n",
        "\n",
        "# Load data\n",
        "\n",
        "\n",
        "# Label mappings\n",
        "label_mapping = {\n",
        "    \"LAYING\": 1,\n",
        "    \"SITTING\": 2,\n",
        "    \"STANDING\": 3,\n",
        "    \"WALKING\": 4,\n",
        "    \"WALKING_DOWNWARDS\": 5,\n",
        "    \"WALKING_UPWARDS\": 6\n",
        "}\n",
        "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
        "\n",
        "# Function to format a single example for few-shot learning\n",
        "def format_example(example):\n",
        "    ax = example[:, 0][:5]  # Increase data points used (5 for more context)\n",
        "    ay = example[:, 1][:5]\n",
        "    az = example[:, 2][:5]\n",
        "\n",
        "    formatted_string = (\n",
        "        f\"ax: {ax}\\n\"\n",
        "        f\"ay: {ay}\\n\"\n",
        "        f\"az: {az}\\n\"\n",
        "        f\"Activity: \"\n",
        "    )\n",
        "\n",
        "    return formatted_string\n",
        "\n",
        "# Prepare few-shot examples with 4 examples per label\n",
        "few_shot_examples = []\n",
        "few_shot_labels = []\n",
        "\n",
        "for label_name, label_id in label_mapping.items():\n",
        "    # Filter examples by label\n",
        "    label_indices = np.where(y_train == label_id)[0]\n",
        "    selected_indices = random.sample(list(label_indices), 4)  # 4 random examples\n",
        "\n",
        "    for idx in selected_indices:\n",
        "        example = X_train[idx]\n",
        "        indices = np.random.choice(example.shape[0], 5, replace=False)  # 5 data points\n",
        "        few_shot_examples.append(example[indices])\n",
        "        few_shot_labels.append(label_id)\n",
        "\n",
        "# Format the few-shot examples with their labels\n",
        "few_shot_prompts = [f\"{format_example(ex)} {reverse_label_mapping[label_id]}\" for ex, label_id in zip(few_shot_examples, few_shot_labels)]\n",
        "\n",
        "# Format input examples from x_test\n",
        "formatted_examples = [format_example(example) for example in X_test]\n",
        "\n",
        "# Combine few-shot prompts with each test example for prediction\n",
        "def create_few_shot_prompt(test_example):\n",
        "    few_shot_section = \"\\n\\n\".join(few_shot_prompts)\n",
        "    return f\"{few_shot_section}\\n\\n{test_example}\"\n",
        "\n",
        "# Initialize the model with the correct model ID\n",
        "model_name = \"llama-3.1-8b-instant\"\n",
        "model = ChatGroq(model_name=model_name, api_key=api_key)\n",
        "\n",
        "# Perform predictions using the ChatGroq model\n",
        "def predict_with_groq(formatted_examples, limit=6):\n",
        "    y_pred = []\n",
        "    for i in range(0, len(formatted_examples), limit):\n",
        "        batch_examples = formatted_examples[i:i+limit]\n",
        "        for example in batch_examples:\n",
        "            # Call the model to get a prediction\n",
        "            response = model.predict(create_few_shot_prompt(example))\n",
        "            y_pred.append(response)\n",
        "    return y_pred\n",
        "\n",
        "# Get predictions for all test examples using the ChatGroq model\n",
        "y_pred = predict_with_groq(formatted_examples, limit=6)\n",
        "\n",
        "# Extract activity labels from the model's response\n",
        "def extract_label(response):\n",
        "    match = re.search(r'\\b(LAYING|SITTING|STANDING|WALKING|WALKING_DOWNWARDS|WALKING_UPWARDS)\\b', response.upper())\n",
        "    return match.group(0) if match else \"UNKNOWN\"\n",
        "\n",
        "# Convert predictions to numeric labels\n",
        "y_pred_labels = [label_mapping.get(extract_label(pred), 0) for pred in y_pred]\n",
        "\n",
        "# Print the numeric predictions for all samples\n",
        "print(\"All predicted labels:\")\n",
        "print(y_pred_labels)\n",
        "\n",
        "print(\"All True labels:\")\n",
        "print(y_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_labels)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDxS5VU_lrha"
      },
      "source": [
        "**Q2)**\n",
        "\n",
        "Decision trees are way more accurate than few-shot prompting, as we custom make a model which works for the accelerometer data, but few-shot prompting matches the examples instead of learning with LLM.\n",
        "\n",
        "Moreover we cannot use all the data as examples for few shot, as we encounter rate limiting errors. But in case of decision trees, we can actually use whole data without any such problems.\n",
        "\n",
        "Also we see latency for API calling in case of few shot, which slows the whole process, though we gave fewer data. But no such thing exists for decision trees."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN-StzuWmyeB"
      },
      "source": [
        "**Q3)**\n",
        "\n",
        "Firstly, both of them use an LLM to predict the accelerometer data, on which no existing LLM is trained as of now. Then we want to predict the data labels using that, so it will not give good accuracies.\n",
        "\n",
        "Also the data loses its value. We know that data is normalized in only [-1,1]. So precision in decimal points hold a significant value, which will be lost in both of the cases.\n",
        "\n",
        "We can hence see why the accuracies are so low for both of them. It doesn't learn anything. In few shot, it creates a bias on where to map the testing data. So, These are all limitations of zero and few shot learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aO39Ogln7ih"
      },
      "source": [
        "**Q4)**\n",
        "\n",
        "Well, when new data is given, the zero-shot still plays mapping to a known existing class. As there are no examples to have bias. Where as few-shot which is expected to give better results as it has examples of it. However, if there is mis-match between training and testing data for few-shot mapping, it will bluntly map to whetever the data is nearest to."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3mzj4X_qJzx"
      },
      "source": [
        "**Q5)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqymLi3tmMCl",
        "outputId": "61c6079d-dce4-4b46-e93e-f20942194862"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random data generated.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Set dimensions\n",
        "train_size = 126\n",
        "test_size = 54\n",
        "timesteps = 500\n",
        "features = 3\n",
        "\n",
        "# Generate random data normalized to [-1, 1]\n",
        "x_train = np.random.uniform(-1, 1, size=(train_size, timesteps, features))\n",
        "x_test = np.random.uniform(-1, 1, size=(test_size, timesteps, features))\n",
        "\n",
        "# Generate random labels for y_train and y_test within the range of your existing labels (1 to 6)\n",
        "y_train = np.random.randint(1, 7, size=(train_size,))\n",
        "y_test = np.random.randint(1, 7, size=(test_size,))\n",
        "\n",
        "# Save the generated data (optional)\n",
        "np.save('Task_3 Random Datasets/X_train_random.npy', x_train)\n",
        "np.save('Task_3 Random Datasets/Y_train_random.npy', y_train)\n",
        "np.save('Task_3 Random Datasets/X_test_random.npy', x_test)\n",
        "np.save('Task_3 Random Datasets/Y_test_random.npy', y_test)\n",
        "\n",
        "print(\"Random data generated.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXbKoEbXrkdV"
      },
      "source": [
        "Zero shot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwwokE2trjug",
        "outputId": "aff03319-4fc1-479b-cada-befa6311cf59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample 1 - Prediction: 0, Actual: 2\n",
            "Sample 2 - Prediction: 0, Actual: 2\n",
            "Sample 3 - Prediction: 2, Actual: 2\n",
            "Sample 4 - Prediction: 0, Actual: 3\n",
            "Sample 5 - Prediction: 0, Actual: 2\n",
            "\n",
            "All predicted labels:\n",
            "[0, 0, 2, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 4, 3, 4, 0, 0, 4, 0, 0, 4, 4, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0]\n",
            "\n",
            "All True labels:\n",
            "[2 2 2 3 2 5 3 4 1 6 4 5 2 6 1 5 4 1 4 6 6 6 5 3 1 5 1 5 6 4 5 1 3 1 1 2 6\n",
            " 6 2 2 3 4 1 2 6 6 1 6 1 5 6 1 3 3]\n",
            "\n",
            "Accuracy: 0.037037037037037035\n"
          ]
        }
      ],
      "source": [
        "# Load the unseen data instead of previously loaded data\n",
        "x_test = np.load('Task_3 Random Datasets/X_test_random.npy')  # Newly generated unseen data\n",
        "y_test = np.load('Task_3 Random Datasets/Y_test_random.npy')  # Newly generated unseen labels\n",
        "\n",
        "# The rest of the code remains unchanged\n",
        "# Perform zero-shot prediction and print raw predictions\n",
        "y_pred = [model.predict(example) for example in formatted_examples]\n",
        "\n",
        "# Extract activity labels from the model's response\n",
        "def extract_label(response):\n",
        "    match = re.search(r'\\b(LAYING|SITTING|STANDING|WALKING|WALKING_DOWNWARDS|WALKING_UPWARDS)\\b', response.upper())\n",
        "    return match.group(0) if match else \"UNKNOWN\"\n",
        "\n",
        "# Convert predictions to numeric labels\n",
        "y_pred_labels = [label_mapping.get(extract_label(pred), 0) for pred in y_pred]\n",
        "\n",
        "# Print raw predictions, predicted labels, and actual labels for the first 10 samples\n",
        "for i in range(5):\n",
        "    raw_pred = y_pred[i]\n",
        "    pred_label = label_mapping.get(extract_label(raw_pred), 0)\n",
        "    actual_label = y_test[i]\n",
        "    print(f\"Sample {i+1} - Prediction: {pred_label}, Actual: {actual_label}\")\n",
        "\n",
        "# Print the numeric predictions for all samples\n",
        "print(\"\\nAll predicted labels:\")\n",
        "print(y_pred_labels)\n",
        "print(\"\\nAll True labels:\")\n",
        "print(y_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_labels)\n",
        "print(f\"\\nAccuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uAWz5iwsuph"
      },
      "source": [
        "Few shot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JfWGaIaswtB",
        "outputId": "90807042-730a-48be-ef29-3ba06a7c41d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All predicted labels:\n",
            "[1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
            "All True labels:\n",
            "[3 1 2 5 5 1 1 5 3 2 6 5 6 5 6 1 6 5 2 5 4 3 2 2 1 4 6 4 1 2 6 2 4 4 3 6 6\n",
            " 3 1 5 3 2 1 4 4 4 5 1 3 3 3 6 2 4]\n",
            "Accuracy: 0.12962962962962962\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from langchain_groq.chat_models import ChatGroq\n",
        "from sklearn.metrics import accuracy_score\n",
        "import re\n",
        "from HAR.MakeDataset import X_train,X_test,y_train,y_test\n",
        "\n",
        "# Label mappings\n",
        "label_mapping = {\n",
        "    \"LAYING\": 1,\n",
        "    \"SITTING\": 2,\n",
        "    \"STANDING\": 3,\n",
        "    \"WALKING\": 4,\n",
        "    \"WALKING_DOWNWARDS\": 5,\n",
        "    \"WALKING_UPWARDS\": 6\n",
        "}\n",
        "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
        "\n",
        "# Function to format a single example for few-shot learning\n",
        "def format_example(example):\n",
        "    ax = example[:, 0][:5]  # Increase data points used (5 for more context)\n",
        "    ay = example[:, 1][:5]\n",
        "    az = example[:, 2][:5]\n",
        "\n",
        "    formatted_string = (\n",
        "        f\"ax: {ax}\\n\"\n",
        "        f\"ay: {ay}\\n\"\n",
        "        f\"az: {az}\\n\"\n",
        "        f\"Activity: \"\n",
        "    )\n",
        "\n",
        "    return formatted_string\n",
        "\n",
        "# Prepare few-shot examples with 4 examples per label\n",
        "few_shot_examples = []\n",
        "few_shot_labels = []\n",
        "\n",
        "for label_name, label_id in label_mapping.items():\n",
        "    # Filter examples by label\n",
        "    label_indices = np.where(y_train == label_id)[0]\n",
        "    selected_indices = random.sample(list(label_indices), 4)  # 4 random examples\n",
        "\n",
        "    for idx in selected_indices:\n",
        "        example = x_train[idx]\n",
        "        indices = np.random.choice(example.shape[0], 5, replace=False)  # 5 data points\n",
        "        few_shot_examples.append(example[indices])\n",
        "        few_shot_labels.append(label_id)\n",
        "\n",
        "# Format the few-shot examples with their labels\n",
        "few_shot_prompts = [f\"{format_example(ex)} {reverse_label_mapping[label_id]}\" for ex, label_id in zip(few_shot_examples, few_shot_labels)]\n",
        "\n",
        "# Format input examples from x_test\n",
        "formatted_examples = [format_example(example) for example in x_test]\n",
        "\n",
        "# Combine few-shot prompts with each test example for prediction\n",
        "def create_few_shot_prompt(test_example):\n",
        "    few_shot_section = \"\\n\\n\".join(few_shot_prompts)\n",
        "    return f\"{few_shot_section}\\n\\n{test_example}\"\n",
        "\n",
        "# Initialize the model with the correct model ID\n",
        "model_name = \"llama-3.1-8b-instant\"\n",
        "model = ChatGroq(model_name=model_name, api_key=api_key)\n",
        "\n",
        "# Perform predictions using the ChatGroq model\n",
        "def predict_with_groq(formatted_examples, limit=6):\n",
        "    y_pred = []\n",
        "    for i in range(0, len(formatted_examples), limit):\n",
        "        batch_examples = formatted_examples[i:i+limit]\n",
        "        for example in batch_examples:\n",
        "            # Call the model to get a prediction\n",
        "            response = model.predict(create_few_shot_prompt(example))\n",
        "            y_pred.append(response)\n",
        "    return y_pred\n",
        "\n",
        "# Get predictions for all test examples using the ChatGroq model\n",
        "y_pred = predict_with_groq(formatted_examples, limit=6)\n",
        "\n",
        "# Extract activity labels from the model's response\n",
        "def extract_label(response):\n",
        "    match = re.search(r'\\b(LAYING|SITTING|STANDING|WALKING|WALKING_DOWNWARDS|WALKING_UPWARDS)\\b', response.upper())\n",
        "    return match.group(0) if match else \"UNKNOWN\"\n",
        "\n",
        "# Convert predictions to numeric labels\n",
        "y_pred_labels = [label_mapping.get(extract_label(pred), 0) for pred in y_pred]\n",
        "\n",
        "# Print the numeric predictions for all samples\n",
        "print(\"All predicted labels:\")\n",
        "print(y_pred_labels)\n",
        "\n",
        "print(\"All True labels:\")\n",
        "print(y_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_labels)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
